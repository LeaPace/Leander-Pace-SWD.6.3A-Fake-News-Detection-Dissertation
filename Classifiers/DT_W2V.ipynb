{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full. W2V import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_comps # Features\n",
    "y = y_prep # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Iteration 0 0.182720953326713\n",
      "Fscore for Iteration 0 0.1732053908091188\n",
      "Precision for Iteration 0 0.1731919975366529\n",
      "Recall for Iteration 0 0.17342216993623324\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Iteration 1 0.1807348560079444\n",
      "Fscore for Iteration 1 0.1701058863419795\n",
      "Precision for Iteration 1 0.17026481254996959\n",
      "Recall for Iteration 1 0.17040956033412705\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Iteration 2 0.17999006951340615\n",
      "Fscore for Iteration 2 0.16989154053470043\n",
      "Precision for Iteration 2 0.1698177438790521\n",
      "Recall for Iteration 2 0.1700106761358197\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Iteration 3 0.18793445878848064\n",
      "Fscore for Iteration 3 0.17781320760406935\n",
      "Precision for Iteration 3 0.17771718899956146\n",
      "Recall for Iteration 3 0.17807878948193068\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy for Iteration 4 0.1829692154915591\n",
      "Fscore for Iteration 4 0.1733861070328018\n",
      "Precision for Iteration 4 0.17330067122464232\n",
      "Recall for Iteration 4 0.17357848231735198\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "rf_accuracy = []\n",
    "rf_fScore = []\n",
    "rf_precision = []\n",
    "rf_recall = []\n",
    "\n",
    "for i in range(5):\n",
    "    #Create a Gaussian Classifier\n",
    "    clf=DecisionTreeClassifier()\n",
    "\n",
    "    #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    y_pred=clf.predict(X_test)\n",
    "\n",
    "    predictions = clf.predict(X_test)\n",
    "    precision,recall,fscore,support=score(y_test,predictions)\n",
    "\n",
    "    print(\"Accuracy for Iteration \" + str(i) + \" \" + str(metrics.accuracy_score(y_test, y_pred)))\n",
    "    rf_accuracy.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print(\"Fscore for Iteration \" + str(i) + \" \" + str(sum(fscore)/len(fscore)))\n",
    "    rf_fScore.append(sum(fscore)/len(fscore))\n",
    "\n",
    "    print(\"Precision for Iteration \" + str(i) + \" \" + str(sum(precision)/len(precision)))\n",
    "    rf_precision.append(sum(precision)/len(precision))\n",
    "    \n",
    "    print(\"Recall for Iteration \" + str(i) + \" \" + str(sum(recall)/len(recall)))\n",
    "    rf_recall.append(sum(recall)/len(recall))\n",
    "\n",
    "    print(\"--------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18286991062562066"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rf_accuracy)/len(rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.172880426464534"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rf_fScore)/len(rf_fScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17285848283797567"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rf_precision)/len(rf_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17309993564109252"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(rf_recall)/len(rf_recall)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1db64c8312b868eab46eb06f4077bc4b407b350787c4625e9af163ad1a2693d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
